---
title: "Motor Failure Prediction – Unit 25"
author: "Noel Sebastia"
date: "2025.01.04"
output:
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# 1. Fundamentos del Aprendizaje Automático (LO1)

## 1.1 ¿Qué es el aprendizaje automático?

El aprendizaje automático (Machine Learning, ML) es una rama de la inteligencia artificial que permite a los sistemas aprender a partir de datos, identificar patrones y tomar decisiones sin estar explícitamente programados para cada tarea. A diferencia de los enfoques clásicos de programación, en los que un programador escribe reglas específicas, en ML se entrena un modelo con datos para que aprenda dichas reglas de forma automática.

En términos generales, un algoritmo de aprendizaje automático analiza conjuntos de datos históricos y desarrolla un modelo estadístico que puede generalizarse a nuevos datos. Esta capacidad de aprendizaje es lo que permite desarrollar sistemas adaptativos y predictivos.

Según Bishop (2006), “el objetivo del aprendizaje automático es desarrollar algoritmos que mejoren su rendimiento automáticamente a través de la experiencia”. Esto permite automatizar tareas complejas como la clasificación de imágenes, la predicción de fallos o el reconocimiento de voz.

> Referencia: Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.


## 1.2 Tipos de aprendizaje automático

El aprendizaje automático puede clasificarse en tres tipos principales:

- **Aprendizaje supervisado:** El modelo se entrena con datos etiquetados (input y output). Ejemplos: regresión lineal, árboles de decisión, SVM, redes neuronales. Se utiliza, por ejemplo, para predecir si un motor fallará basándose en lecturas de sensores.

- **Aprendizaje no supervisado:** El modelo trabaja con datos no etiquetados para encontrar estructuras o patrones ocultos. Ejemplos: clustering (K-means), reducción de dimensionalidad (PCA).

- **Aprendizaje por refuerzo:** El sistema aprende mediante prueba y error, maximizando una recompensa a largo plazo. Se aplica comúnmente en robótica, juegos o control industrial.

En este trabajo, el enfoque será el aprendizaje **supervisado**, ya que se dispone de datos etiquetados indicando si un motor ha fallado o no.

## 1.3 ¿Qué es una máquina inteligente?

Una máquina inteligente es un sistema capaz de percibir su entorno, analizar datos, aprender de la experiencia y tomar decisiones de forma autónoma o asistida. Su comportamiento no depende únicamente de reglas programadas previamente, sino que evoluciona con la información que recibe.

Estas máquinas combinan sensores, algoritmos de procesamiento, capacidad de almacenamiento y mecanismos de decisión adaptativos. En el contexto de la industria, esto puede abarcar desde un sistema de climatización que ajusta su rendimiento según patrones de uso, hasta motores que se auto-diagnostican y predicen fallos futuros.

Las máquinas inteligentes representan un paso más allá de la automatización tradicional, ya que integran inteligencia en la operación y no sólo ejecución de instrucciones.

## 1.4 ¿Por qué el aprendizaje automático es esencial para diseñarlas?

El aprendizaje automático es la base del comportamiento inteligente en sistemas modernos. Sin él, las máquinas están limitadas a lo que el programador haya previsto. Con ML, en cambio, los sistemas pueden:

- **Aprender y adaptarse**: Cambian su comportamiento en función de nuevos datos.
- **Detectar patrones complejos**: Por ejemplo, vibraciones anómalas que preceden a una avería.
- **Reducir la intervención humana**: Automatizan tareas de diagnóstico o predicción.
- **Mejorar con el tiempo**: Aumentan su precisión cuanto más datos procesan.

En el campo del mantenimiento industrial, el ML es esencial para la transición del mantenimiento reactivo al **mantenimiento predictivo**, en el cual los sistemas detectan condiciones anómalas antes de que ocurran fallos graves.

Como indica Russell y Norvig (2020), el aprendizaje automático transforma datos en conocimiento operativo, lo cual es indispensable para la inteligencia de sistemas complejos.

> Referencia: Russell, S. J. & Norvig, P. (2020). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.

## 1.5 Aplicación al caso: Predicción de fallo en motores

En este trabajo se aplicará el aprendizaje automático a un problema industrial real: predecir el fallo de motores eléctricos mediante datos captados por sensores. Estos motores son elementos clave en muchas líneas de producción, y su parada inesperada genera importantes costes económicos y logísticos.

Mediante el uso de modelos de ML y datos como temperatura, vibración, humedad o carga, es posible entrenar un sistema que anticipe cuándo un motor está cerca de fallar. Esto convierte al sistema en una máquina inteligente capaz de:

- Evaluar su estado interno en tiempo real.
- Alertar al operario antes del fallo.
- Posiblemente, indicar la **causa más probable del fallo** si se extiende el modelo.

El uso de estos sistemas reduce tiempos de inactividad, mejora la planificación del mantenimiento y aumenta la seguridad operativa. Además, se puede ampliar el enfoque a distintas clases de fallo (eléctrico, mecánico, por sobreuso), lo que permitiría diagnósticos más específicos.

Este tipo de solución ilustra perfectamente cómo el aprendizaje automático contribuye al diseño de máquinas inteligentes dentro del entorno industrial.

> Referencia: Ghosh, S. et al. (2021). *Predictive Maintenance using Machine Learning*. Springer.


# 2. Presentación y origen del dataset

## 2.1 Descripción del dataset

El conjunto de datos utilizado en este trabajo proviene de un entorno industrial simulado diseñado para el estudio del mantenimiento predictivo en sistemas rotativos. Fue obtenido del repositorio oficial UCI Machine Learning Repository (AI4I 2020 Predictive Maintenance Dataset) y contiene un total de 1.000 registros y 10 variables que representan mediciones relevantes para diagnosticar el estado de funcionamiento de un sistema rotativo o motor.

Las variables incluidas en el dataset son:

- `UDI`: Identificador único del registro (numérico).
- `Product ID`: Código del producto o motor (carácter).
- `Type`: Tipo de motor, clasificado como `H` (High), `L` (Low) o `M` (Medium).
- `Air temperature [K]`: Temperatura del aire medida en Kelvin.
- `Process temperature [K]`: Temperatura del proceso industrial (Kelvin).
- `Rotational speed [rpm]`: Velocidad de rotación en revoluciones por minuto.
- `Torque [Nm]`: Par de torsión aplicado al motor (Newton-metros).
- `Tool wear [min]`: Desgaste de la herramienta en minutos acumulados.
- `Target`: Variable binaria que indica si hubo un fallo (1) o no (0).
- `Failure Type`: Tipo específico de fallo registrado, como por ejemplo "Power Failure" o "Tool Wear Failure".

El dataset está completamente limpio, sin valores faltantes en ninguna de las columnas. Las clases de fallo están desbalanceadas: un 70% de las muestras corresponden a motores sin fallo (`Target = 0`) y el 30% presentan algún tipo de fallo (`Target = 1`). Entre las categorías de fallo más frecuentes se encuentran "Tool Wear Failure" (119 casos) y "Heat Dissipation Failure" (43 casos).

En cuanto a los sensores, las variables numéricas como la temperatura, la velocidad rotacional o el torque presentan rangos coherentes con un entorno industrial, con valores como:

- `Air temperature [K]`: Media de 300.1K (~27°C), rango entre 294.2K y 305.3K.
- `Rotational speed [rpm]`: Media de 1500 rpm, valores entre 1201 y 1893 rpm.
- `Torque [Nm]`: Media de 39.4 Nm, variando desde 9.9 hasta 72.4 Nm.

Este dataset es adecuado para construir modelos supervisados de clasificación que permitan predecir la ocurrencia de fallos basándose en los datos capturados por los sensores.

## 2.2 Objetivo del análisis

El objetivo principal de este proyecto es construir un modelo de aprendizaje automático que permita predecir si un motor eléctrico fallará en función de los datos sensoriales registrados durante su operación. Esto se traduce en un problema de **clasificación binaria supervisada**, donde la variable objetivo (`Target`) toma los valores 0 (sin fallo) o 1 (con fallo).

Este tipo de predicción es crucial en contextos industriales porque permite anticiparse a posibles interrupciones de producción, programar mantenimientos preventivos y evitar fallos catastróficos que afecten la seguridad o la eficiencia operativa.

Como extensión futura, se plantea la posibilidad de realizar una **clasificación multiclase** que no sólo indique la ocurrencia de un fallo, sino que también determine su **tipo probable** (por ejemplo: fallo por sobreesfuerzo, fallo eléctrico, desgaste de herramienta, etc.), utilizando la columna `Failure Type` como variable objetivo.

---

# 3. Análisis exploratorio de datos (EDA)

Este apartado tiene como objetivo comprender el comportamiento de las variables del dataset y justificar cada decisión tomada antes de construir el modelo predictivo. Cada gráfico se incluye con una intención específica: evaluar la calidad de los datos, detectar patrones relevantes para la predicción o anticipar decisiones de preprocesado.

```{r load-data}
# Cargar librerías necesarias
library(tidyverse)
library(ggplot2)
library(readr)
library(DT)

df <- read_csv("data/predictive_maintenance.csv")

head(df)
```

La tabla anterior muestra las primeras filas del dataset, lo que permite una primera inspección visual de su estructura. Se observan variables numéricas como Rotational speed [rpm], Torque [Nm] o Tool wear [min], así como variables categóricas (Type) e identificadores (UDI, Product ID). Esta revisión inicial permite identificar rápidamente el tipo de datos presentes, su formato y si contienen valores anómalos evidentes.

## 3.1 Estructura y limpieza de datos

Antes de aplicar cualquier técnica de análisis o modelado, es fundamental **verificar la integridad del dataset**, especialmente la presencia de valores faltantes. Esto permite determinar si es necesario aplicar métodos de imputación, eliminar registros incompletos o si se puede continuar con el conjunto de datos tal como está.

```{r load-packages}
colSums(is.na(df))
```

La salida de este comando indica que **no existen valores NA en ninguna de las columnas**. Por tanto, se confirma que el dataset está completamente limpio en cuanto a datos ausentes, lo cual simplifica el proceso de preprocesado posterior y evita posibles sesgos derivados de imputaciones artificiales.

## 3.2 Distribución de la variable objetivo (Target)

Antes de aplicar cualquier modelo de clasificación, es importante entender cómo se distribuyen las clases en la variable objetivo. En este caso, `Target` indica si un motor ha fallado (`1`) o no (`0`). Analizar su distribución permite anticipar si será necesario aplicar técnicas de balanceo de clases.

```{r Target-distribution}
ggplot(df, aes(x = factor(Target))) +
  geom_bar(fill = "steelblue") +
  labs(title = "Distribución de la variable objetivo (Target)", x = "Fallo", y = "Cantidad")
```

El gráfico de barras muestra que aproximadamente el **70% de los motores no presentan fallos**, mientras que el **30% sí fallan**. Este **desbalance moderado** es relevante, ya que puede afectar el rendimiento de los modelos de clasificación, haciéndolos propensos a favorecer la clase mayoritaria.

Por tanto, este análisis justifica el uso posterior de técnicas como el **sobremuestreo (upsampling)** para equilibrar la representación de clases durante el entrenamiento y mejorar la capacidad del modelo para detectar fallos.

## 3.3 Distribución de variables numéricas relevantes

En este apartado se analizan algunas de las variables numéricas más representativas del estado operativo del motor. El objetivo es comprender su distribución, identificar posibles valores atípicos y evaluar su comportamiento antes del modelado. Las variables seleccionadas han sido escogidas por su **relación directa con el rendimiento o desgaste del motor**, según la documentación del dataset.

### Temperatura del aire (`Air temperature [K]`)

La temperatura ambiente afecta directamente a la eficiencia térmica del motor. Se analiza su distribución para detectar sesgos o valores extremos que puedan requerir transformación o tratamiento adicional.

En esta sección se representa la temperatura en su forma original, Kelvin, tal como aparece en el dataset bruto. Aunque esta unidad es válida físicamente, en la etapa de preprocesamiento (Sección 4) se convertirá a grados Celsius.

```{r air-temperature}
ggplot(df, aes(x = `Air temperature [K]`)) +
  geom_histogram(bins = 30, fill = "tomato", color = "black") +
  labs(title = "Temperatura del aire (K)", x = "Kelvin", y = "Frecuencia")
```

La variable presenta una distribución **ligeramente sesgada**, pero **aproximadamente normal**, lo cual sugiere que puede utilizarse directamente en los modelos sin necesidad de transformación. No se observan valores atípicos evidentes.

En el preprocesado posterior, esta variable será transformada a grados Celsius para facilitar su interpretación.

### Torque (`Torque [Nm]`)

El torque mide la fuerza de rotación aplicada, siendo un parámetro clave en condiciones de carga. Se visualiza para identificar su comportamiento general y evaluar su relación potencial con el fallo del motor.

```{r torque}
ggplot(df, aes(x = `Torque [Nm]`)) +
  geom_histogram(bins = 30, fill = "darkgreen", color = "black") +
  labs(title = "Distribución del Torque", x = "Nm", y = "Frecuencia")
```

El torque presenta una **distribución ligeramente sesgada hacia la izquierda**, con un único pico principal alrededor de 40 Nm. No se observan modos secundarios que sugieran regímenes de operación diferenciados, pero la forma de la distribución podría estar relacionada con distintas cargas aplicadas durante el uso. Este comportamiento justifica su inclusión como predictor clave en el modelo.

### Velocidad rotacional (`Rotational speed [rpm]`) por tipo de motor (`Type`)

En lugar de graficar la distribución general, se ha optado por un **boxplot por tipo de motor**, ya que la variable `Type` segmenta los motores según su capacidad o configuración. Esto permite comparar directamente si existen diferencias operativas entre tipos.

```{r rotational-speed}
ggplot(df, aes(x = Type, y = `Rotational speed [rpm]`, fill = Type)) +
  geom_boxplot() +
  labs(title = "Velocidad rotacional por tipo de motor", x = "Tipo", y = "RPM")
```

El gráfico de boxplot permite comparar la distribución de la velocidad rotacional (`RPM`) entre los distintos tipos de motor (`Type`). Aunque **las medianas y rangos centrales son bastante similares** para los tres grupos (`L`, `M`, `H`), se observa la presencia de **algunos valores atípicos**, especialmente en los tipos `H` y `M`.

Estos valores extremos podrían reflejar **condiciones operativas poco frecuentes** o situaciones de carga elevada, lo que **refuerza la idea de que tanto** `Type` **como** `Rotational speed [rpm]` **podrían ser variables predictoras importantes** en la detección de fallos.

## 3.4 Correlaciones entre variables

Antes de entrenar modelos de tipo lineal, como la regresión logística, es importante analizar las correlaciones entre variables numéricas. El objetivo es **detectar relaciones lineales fuertes que puedan generar multicolinealidad**, es decir, redundancia estadística entre predictores. Este fenómeno puede afectar tanto la interpretación del modelo como su estabilidad y rendimiento.

En este análisis se incluyen únicamente variables numéricas relevantes desde el punto de vista operativo. Se han excluido variables duplicadas en diferentes unidades (como las temperaturas en Kelvin y Celsius) y campos identificadores como `UDI`.

```{r correlations}
library(corrplot)
numeric_vars <- df %>%
  select(`Rotational speed [rpm]`, `Torque [Nm]`, `Tool wear [min]`,
         `Air temperature [K]`, Target)

cor_matrix <- cor(numeric_vars)
corrplot(cor_matrix, method = "color", type = "upper",
         col = colorRampPalette(c("blue", "white", "red"))(200),
         tl.col = "black", addCoef.col = "black")
```

El gráfico obtenido muestra que **no existe una correlación lineal fuerte entre las variables analizadas**. De hecho, la mayoría de coeficientes de correlación están muy próximos a cero, indicando independencia lineal.

Algunas observaciones específicas:

- La mayor correlación observada es entre `Air temperature [C]` y `Torque [Nm]`, pero apenas alcanza un valor de **-0.06**, lo que no es estadísticamente significativo.

- Otras relaciones como entre `Torque` y `Tool wear`, o `Rotational speed` y `Target`, también muestran coeficientes **cercanos a cero**.

- Esto indica que **no hay redundancia estadística evidente** entre los predictores, al menos desde el punto de vista de la correlación lineal.

Este resultado sugiere que las variables pueden aportar información complementaria al modelo, lo que es positivo para la construcción de predictores independientes. La multicolinealidad será, no obstante, evaluada más adelante mediante el análisis de VIF tras el preprocesamiento.

---

# 4. Preparación de los datos

Antes de entrenar cualquier modelo de aprendizaje automático, es imprescindible preparar adecuadamente los datos. Esta fase tiene un impacto directo en el rendimiento y la interpretabilidad del modelo. En este caso, se han llevado a cabo las siguientes acciones:

- **Conversión de unidades**: Las temperaturas originalmente estaban expresadas en Kelvin. Aunque es una unidad válida desde el punto de vista físico, se decidió convertirlas a grados Celsius para facilitar su análisis e interpretación por parte de técnicos y responsables industriales.

- **Eliminación de columnas irrelevantes**: Se eliminaron `UDI` y `Product ID` por ser identificadores sin información predictiva. También se eliminaron `Air temperature [K]` y `Process temperature [K]` tras calcular sus equivalentes en °C, evitando así redundancias que podrían interferir con el aprendizaje del modelo.

- **Tratamiento de variables categóricas**: La variable `Type`, que indica el tipo de motor (H, M, L), fue inicialmente codificada como dummies (*one-hot encoding*). Sin embargo, tras una revisión metodológica, se decidió tratarla como un factor. Esto permite a ciertos algoritmos (*como la regresión logística en R*) manejarla de forma más eficiente y evita introducir colinealidad innecesaria entre columnas.

- **Balanceo de clases**: Dado que solo el 30% de los motores presentan fallo (Target = 1), se aplicó sobremuestreo para igualar ambas clases en el conjunto de entrenamiento. Esta estrategia mejora la sensibilidad del modelo hacia la clase minoritaria y reduce el riesgo de un sesgo hacia la clase mayoritaria.

- **Verificación de multicolinealidad**: Como paso final del preprocesado, se ha evaluado la independencia estadística entre predictores mediante el análisis del **Factor de Inflación de Varianza** (VIF). Esto es especialmente relevante antes de entrenar modelos lineales como la regresión logística

El preprocesado de datos incluye una etapa crítica cuando se trabaja con conjuntos desbalanceados: el *up-sampling*. Esta técnica consiste en aumentar artificialmente el número de muestras de la clase minoritaria (en nuestro caso, los motores con fallo), duplicando aleatoriamente ejemplos de esa clase hasta igualar el número de la clase mayoritaria.

El objetivo del *up-sampling* es evitar que el modelo aprenda a ignorar la clase minoritaria por su baja representación. Esto mejora métricas como la sensibilidad (recall) y el F1-score en problemas donde detectar la clase minoritaria (fallos) es crítico. Sin embargo, también incrementa el riesgo de *overfitting* si se aplicara en exceso, ya que se repiten datos existentes en lugar de aportar ejemplos nuevos.

En este proyecto, se ha utilizado la función `upSample()` del paquete `caret` para igualar el número de casos con y sin fallo antes de entrenar el modelo.

## 4.1 Conversión de unidades

Como parte del preprocesamiento, se convierte la variable Air temperature [K] a grados Celsius (Air temperature [C]) para facilitar su interpretación. La versión en Kelvin será eliminada en el siguiente paso para evitar redundancias.

```{r convert-units}
df$`Air temperature [C]` <- df$`Air temperature [K]` - 273.15

ggplot(df, aes(x = `Air temperature [C]`)) +
  geom_histogram(bins = 30, fill = "tomato", color = "black") +
  labs(title = "Distribución de la temperatura del aire (°C)",
       x = "°C", y = "Frecuencia")
```

Esta nueva visualización confirma que, tras la conversión, la **distribución de la temperatura en grados Celsius mantiene su forma aproximadamente normal**, sin presencia de valores extremos. Esta transformación no altera el comportamiento estadístico de la variable, pero **sí mejora su interpretabilidad**.

## 4.2 Eliminación de variables redundantes

```{r remove-redundant}
df <- df %>% select(-UDI, -`Product ID`, -`Air temperature [K]`, -`Process temperature [K]`)

head(df)
```

`UDI` y `Product ID`: identificadores únicos, sin correlación con la variable objetivo ni uso práctico para predicción.

`Air temperature [K]` y `Process temperature [K]`: sus equivalentes en °C ya fueron generados previamente para facilitar análisis más intuitivos, por lo que mantener ambas versiones genera redundancia y puede afectar a los modelos.

Tras este paso, el conjunto de datos ya no incluye columnas irrelevantes como `UDI`, `Product ID`, ni versiones duplicadas de temperatura en Kelvin. Esto puede verificarse observando el contenido actual del dataset (`head(df)`), donde solo permanecen las variables con valor predictivo real y sin redundancias.

## 4.3 Conversión de variables categóricas

```{r convert-categorical}
df$Type <- as.factor(df$Type)
df$Target <- as.factor(df$Target)

head(df)
```

Aunque `Target` ya contiene valores 0 y 1, se convierte en factor para asegurar que se trata como una variable categórica en los modelos de clasificación. Esto también evita que ciertas funciones interpreten erróneamente la variable como continua. La conversión de `Type` permite que modelos como `glm()` o árboles de decisión puedan interpretar directamente la categoría sin codificación adicional.

Como resultado de esta transformación, las variables `Type` y `Target` ahora aparecen como factores (`<fctr>`), lo que indica que han pasado a tratarse correctamente como categorías en el análisis. Esto puede verse en la cabecera del dataset, donde antes `Type` era una cadena de caracteres (`<chr>`) y ahora se interpreta como factor, permitiendo un tratamiento adecuado en modelos de clasificación.

## 4.4 Balanceo de clases

Dado el desbalance observado en la variable Target, se procede a aplicar **upsampling** para equilibrar el conjunto de entrenamiento. A continuación se muestra la distribución original de clases:

```{r unbalanced-classes}
table(df$Target)
```

Se observa que la clase 0 (sin fallo) tiene más del doble de ejemplos que la clase 1 (fallo), lo que podría sesgar el modelo hacia la clase mayoritaria.

La técnica de upsampling se aplicó usando `caret::upSample()`, que genera copias aleatorias de ejemplos de la clase minoritaria hasta igualar su número con la clase mayoritaria. Esto es fundamental en problemas donde el costo de un falso negativo (no detectar un fallo) es mucho mayor que el de un falso positivo. 

Aunque aumenta el riesgo de *overfitting*, en este caso está justificado debido al desequilibrio moderado y al uso de modelos base.

```{r balance-classes}
library(caret)

set.seed(123)
df_balanced <- upSample(x = df[, -which(names(df) == "Target")],
                        y = df$Target,
                        yname = "Target")

# Comprobar nuevo balance
table(df_balanced$Target)
```

La nueva tabla muestra que ambas clases (`0` y `1`) tienen ahora la misma cantidad de ejemplos (700 cada una), lo cual permite entrenar modelos más balanceados y sensibles a los fallos reales.

## 4.5 Verificación de multicolinealidad tras el preprocesado

Una vez creado el conjunto balanceado de datos (`df_balanced`), se ha procedido a comprobar la **multicolinealidad entre predictores** mediante el cálculo del **Variance Inflation Factor (VIF)**. Este análisis es clave antes de entrenar modelos lineales, ya que la presencia de colinealidad puede afectar negativamente tanto al ajuste como a la interpretación de los coeficientes del modelo.

El análisis se ha realizado utilizando el conjunto balanceado completo, justo antes de dividir en entrenamiento y test. En el caso de variables categóricas como `Type` y `Failure Type`, el modelo calcula el **Generalized VIF (GVIF)**, que se ajusta en función del número de niveles del factor. Para interpretar correctamente estos valores, se utiliza la transformación estándar `GVIF^(1/(2*Df))`, que permite comparar todos los predictores en la misma escala.


```{r vif-after-preprocessing}
library(car)
model_vif <- glm(Target ~ ., data = df_balanced, family = binomial())
vif_values <- vif(model_vif)
print(vif_values)
```

Resumen de los valores ajustados de VIF (GVIF^(1/(2*Df))):

- **Type**: 1.0107
- **Rotational speed [rpm]**: 1.0144
- **Torque [Nm]**: 1.0129
- **Tool wear [min]**: 1.0083
- **Failure Type**: 1.0084
- **Air temperature [C]**: 1.0132

Todos los valores están muy próximos a 1, lo que indica una colinealidad prácticamente inexistente entre los predictores del modelo. Esto es especialmente positivo, ya que refuerza la independencia de las variables seleccionadas y evita distorsiones en la estimación de los coeficientes.

Ninguno de los predictores supera el umbral habitual de 5 (considerado como colinealidad moderada), ni mucho menos el valor de 10 (colinealidad severa). Por tanto, no es necesario eliminar ni transformar ninguna variable adicional en esta etapa.

---

# 5. Modelado

## 5.1 Algoritmo(s) utilizados

Para esta primera aproximación, se ha optado por utilizar un modelo de **regresión logística**, una técnica clásica pero potente para problemas de **clasificación binaria**. Su funcionamiento se basa en estimar la probabilidad de pertenencia a una clase en función de una combinación lineal de las variables predictoras, transformada mediante una función logística (sigmoide).

Este modelo es especialmente útil por varias razones:

- **Interpretabilidad**: permite identificar fácilmente qué variables tienen mayor peso en la predicción del fallo, lo cual es valioso en contextos industriales donde se requiere justificar las decisiones.

- **Velocidad y simplicidad**: es rápido de entrenar y no requiere grandes cantidades de datos ni un ajuste excesivo de hiperparámetros.

- **Robustez**: cuando los predictores están correctamente preparados y no presentan multicolinealidad, como es el caso tras el análisis con VIF, el modelo suele ofrecer buenos resultados iniciales.

Aunque la regresión logística es un modelo lineal, ofrece una línea base de rendimiento razonable con la que se pueden comparar otros algoritmos más complejos. En secciones posteriores se evaluará también el comportamiento de un modelo Naïve Bayes, con el objetivo de explorar posibles diferencias en rendimiento y sensibilidad frente al tamaño de muestra.

## 5.2 División train/test

Con el objetivo de evaluar la capacidad de generalización del modelo, se ha dividido el conjunto de datos balanceado (`df_balanced`) en dos subconjuntos:

**80% para entrenamiento**, donde el modelo aprende los patrones a partir de los datos.

**20% para test**, que se reserva para una evaluación objetiva del rendimiento sobre datos no vistos durante el entrenamiento.

Esta división se realiza utilizando la función `createDataPartition()` del paquete `caret`, que además de dividir aleatoriamente, estratifica automáticamente la variable objetivo (`Target`). Esto asegura que ambas clases (fallo/no fallo) se mantengan en proporciones similares tanto en el conjunto de entrenamiento como en el de test, lo cual es especialmente relevante en problemas de clasificación binaria.

```{r split-data}
# Cargar librerías necesarias
library(caret)
library(e1071)
set.seed(123)

# División en entrenamiento y test
trainIndex <- createDataPartition(df_balanced$Target, p = 0.8, list = FALSE)
trainData <- df_balanced[trainIndex, ]
testData  <- df_balanced[-trainIndex, ]
```

Esta separación permite una evaluación más fiable del rendimiento del modelo, minimizando el riesgo de sobreajuste (overfitting) al asegurar que las predicciones se validan con observaciones independientes del proceso de entrenamiento.

## 5.3 Entrenamiento del modelo

El modelo de **regresión logística** se ha entrenado utilizando el conjunto de entrenamiento definido en el paso anterior. Esta técnica permite modelar la probabilidad de que un motor falle (`Target = 1`) en función de las variables sensoriales disponibles, como torque, velocidad de rotación o temperatura.

El entrenamiento se ha llevado a cabo con la función `train()` del paquete `caret`, que proporciona una interfaz uniforme para entrenar modelos y realizar validación cruzada de forma automatizada. En este caso, se ha especificado el método `"glm"` (generalized linear model) con familia `"binomial"` para resolver un problema de clasificación binaria.

```{r model-training}
# Entrenamiento con regresión logística
model_log <- train(Target ~ ., data = trainData, method = "glm", family = "binomial")
```

Este proceso ajusta los coeficientes del modelo para minimizar la devianza residual, una medida que indica la discrepancia entre los valores observados y los predichos por el modelo. El resultado es una función logística que estima la probabilidad de fallo para cada observación en base a sus características.

## 5.4 Evaluación del modelo

Una vez entrenado el modelo de regresión logística, se ha evaluado su rendimiento utilizando el conjunto de test. Para ello, se generan predicciones sobre datos no vistos durante el entrenamiento y se comparan con las etiquetas reales. El análisis se realiza mediante una matriz de confusión, a partir de la cual se calculan métricas fundamentales en clasificación binaria:

- **Accuracy**: proporción de predicciones correctas sobre el total.

- **Sensitivity (Recall)**: capacidad del modelo para detectar correctamente los casos positivos (fallos).

- **Specificity**: capacidad de identificar correctamente los casos negativos (sin fallo).

- **Precision**: proporción de verdaderos positivos entre los predichos como positivos.

- **F1-score**: media armónica entre precisión y recall, útil especialmente con clases desbalanceadas.

- **Kappa**: coeficiente que mide la concordancia entre predicción y realidad, ajustado por azar.

```{r model-evaluation}
# Predicción
predictions <- predict(model_log, newdata = testData)

# Matriz de confusión y métricas
confusionMatrix(predictions, testData$Target)
```

En este caso, el modelo alcanzó un rendimiento **perfecto** sobre el conjunto de test, con los siguientes resultados:

- **Accuracy**: 1.0 (100% de aciertos)
- **Sensitivity (Recall)**: 1.0
- **Specificity**: 1.0
- **Pos Pred Value (Precision)**: 1.0
- **Negative Predictive Value**: 1.00
- **Balanced Accuracy**: 1.0
- **Kappa**: 1.0
- **No Information Rate (NIR)**: 0.5
- **P-Value [Acc > NIR]**: < 2.2e-16 (indica que el modelo es significativamente mejor que una predicción aleatoria)

La matriz de confusión muestra 140 predicciones correctas para cada clase y ningún error de clasificación.

Aunque este rendimiento puede parecer ideal, debe interpretarse con precaución:

- El conjunto fue balanceado artificialmente mediante upsampling, lo que facilita el aprendizaje del modelo.

- Los datos de test provienen del mismo origen que los de entrenamiento, lo que reduce la heterogeneidad.

- La validación cruzada y la evaluación sobre un conjunto no balanceado serían pasos importantes para confirmar la robustez del modelo.

## 5.5 Evaluación del riesgo de overfitting

Aunque el modelo de regresión logística alcanza una precisión perfecta del 100% tanto en el conjunto de test como en la matriz de confusión, este resultado debe interpretarse con cautela. En contextos reales, una predicción sin errores es extremadamente poco común y puede ser indicativa de **sobreajuste** (*overfitting*), especialmente cuando se ha utilizado *up-sampling*, que consiste en duplicar instancias de la clase minoritaria para equilibrar el dataset.

Para evaluar si el modelo realmente generaliza bien o si está memorizando patrones específicos, se ha aplicado una técnica robusta: la **validación cruzada de 10 particiones (10-fold cross-validation)**. Esta estrategia divide el dataset balanceado (`df_balanced`) en 10 subconjuntos (folds), y entrena y valida el modelo en diferentes combinaciones de estos, minimizando el riesgo de obtener resultados sesgados debido a una división aleatoria favorable.

```{r overfitting-evaluation}
library(caret)

# Control con validación cruzada de 10 particiones
train_control <- trainControl(method = "cv", number = 10)

# Entrenar modelo con CV
model_cv <- train(Target ~ ., data = df_balanced, 
                  method = "glm", family = "binomial",
                  trControl = train_control)

print(model_cv)
```

Los resultados muestran un **Accuracy (media)**: 1.00 y un valor **Kappa**: 1.00.

Estos valores confirman que el modelo mantiene un rendimiento perfecto incluso bajo validación cruzada, lo cual refuerza su consistencia. No obstante, este comportamiento podría deberse a ciertas características del dataset, como una **alta separabilidad entre clases**, un **diseño experimental simulado** o la **limpieza extrema de los datos**.

Aunque los resultados sugieren que el modelo generaliza correctamente en este entorno, no puede descartarse completamente la posibilidad de sobreajuste, ya que el balanceo mediante duplicación podría facilitar que el modelo memorice ejemplos en lugar de aprender patrones generalizables.

Para validar su robustez en escenarios más realistas, se recomienda en futuras iteraciones evaluar el modelo sobre un conjunto externo real no balanceado, comparar con otros algoritmos más complejos (Random Forest, XGBoost) y/o analizar la estabilidad del modelo ante ruido o registros incompletos.

Este enfoque permitirá comprobar su aplicabilidad en entornos industriales reales, donde los datos no siempre cumplen condiciones ideales. Aun así, los resultados actuales constituyen una excelente base inicial para validar la viabilidad de modelos predictivos en mantenimiento industrial.

## 5.6 Análisis de residuos: homocedasticidad y linealidad

En modelos lineales clásicos, como la regresión lineal, es habitual analizar los residuos frente a los valores ajustados para comprobar si se cumplen ciertos supuestos fundamentales del modelo. Entre ellos, destacan dos:

- **Linealidad**: se refiere a que la relación entre las variables predictoras y la variable dependiente debe ser aproximadamente lineal. En otras palabras, el efecto de cada predictor sobre la variable objetivo debe poder representarse con una línea recta.

- **Homocedasticidad**: significa que la **varianza de los errores (residuos)** debe ser constante a lo largo de todos los niveles de las variables independientes. Si la varianza de los errores cambia (por ejemplo, crece o disminuye con el valor ajustado), se habla de **heterocedasticidad**, lo que puede afectar la validez de las inferencias estadísticas en un modelo lineal.

Sin embargo, en el caso de la **regresión logística**, estos supuestos **no se aplican de forma directa**:

- El modelo estima probabilidades, no valores continuos, por lo que la relación esperada no es lineal entre predictores y la variable dependiente, sino entre los predictores y el **logit** (logaritmo del cociente de probabilidades).

- Los residuos deviance no siguen una distribución continua ni presentan varianza constante, por lo que el supuesto de homocedasticidad **no tiene sentido en este contexto**.

Por estos motivos, se ha decidido no representar el gráfico de residuos frente a valores ajustados, ya que su uso, aunque frecuente en regresión lineal, no es válido ni informativo para evaluar una regresión logística.

Este apartado se mantiene como reflexión crítica, ya que en entregas anteriores se sugirió realizar este tipo de análisis. A partir de la revisión bibliográfica y metodológica, se ha optado por omitirlo conscientemente, sustituyéndolo por herramientas más adecuadas para modelos de clasificación: **validación cruzada**, **métricas de rendimiento** y **análisis de colinealidad**.

## 5.7 Evaluación alternativa con Naïve Bayes

Con el objetivo de comparar la regresión logística con otro enfoque clásico de clasificación, se ha evaluado también un modelo basado en **Naïve Bayes**. Este algoritmo se basa en el **teorema de Bayes** con una fuerte suposición de **independencia condicional entre los predictores**, lo cual rara vez se cumple en la práctica. Aun así, Naïve Bayes suele ofrecer buenos resultados en muchos problemas reales debido a su simplicidad y eficiencia.

Además, Naïve Bayes es un modelo **rápido, simple y eficaz con pocos datos**, lo que lo convierte en una opción interesante en escenarios industriales con recursos computacionales limitados o necesidad de respuesta en tiempo real.

En este experimento, se comparó su rendimiento frente al modelo de regresión logística utilizando el mismo conjunto de datos balanceado y una validación cruzada de 10 particiones (*10-fold cross-validation*), para garantizar una evaluación justa y coherente.

### Entrenamiento del modelo

```{r naive-bayes}
# Definir control de validación cruzada
train_control <- trainControl(method = "cv", number = 10)

# Entrenar modelo Naïve Bayes
model_nb <- train(Target ~ ., data = df_balanced,
                  method = "naive_bayes",
                  trControl = train_control)
print(model_nb)
```

Durante el proceso, se evaluaron dos variantes del modelo: con y sin estimación kernel de las distribuciones. Los valores finales seleccionados automáticamente fueron:

- `usekernel = TRUE`

- `laplace` = 0

- `adjust` = 1

El modelo **sin kernel** obtuvo un rendimiento bajo (67.5% de aciertos), lo que sugiere que **la suposición de independencia condicional y distribución normal de los predictores no se cumple** en este conjunto de datos.

Por el contrario, al activar la opción `usekernel = TRUE`, que permite estimar las distribuciones de forma no paramétrica, el rendimiento mejoró drásticamente, alcanzando una precisión del **99.93%** y un índice Kappa de **0.9986**, muy cercano al rendimiento perfecto de la regresión logística.

Este experimento demuestra que con una mínima adaptación (uso de kernel), **Naïve Bayes puede ser altamente competitivo**, incluso sin necesidad de estructuras complejas ni ajustes exhaustivos. A pesar de su simplicidad, el modelo logra un rendimiento excelente gracias a la calidad del preprocesado y la separabilidad de las clases en el dataset.

---

# 6. Conclusiones

### Primera Entrega Intermedia:

El modelo de regresión logística entrenado sobre el conjunto balanceado ha mostrado un rendimiento **perfecto** sobre los datos de test. La precisión global fue del **100%**, sin errores en la predicción de ninguna clase.

La matriz de confusión indica que todos los motores fueron correctamente clasificados como fallidos o no fallidos. Las métricas fueron:

- **Accuracy**: 1.0
- **Precision**: 1.0
- **Recall**: 1.0
- **F1-score**: 1.0

Este comportamiento ideal puede deberse a una combinación de un conjunto de datos bien definido, un modelo simple pero efectivo, y la técnica de *up-sampling* que ayudó a equilibrar correctamente las clases. Aun así, es recomendable evaluar este modelo con nuevas particiones o validación cruzada para asegurar que no hay sobreajuste.

Las variables que más influyeron en las predicciones fueron:
- `Torque [Nm]`
- `Rotational speed [rpm]`
- `Tool wear [min]`

Como mejora futura, se pueden probar otros algoritmos (Random Forest, XGBoost), ajustar umbrales de clasificación para contextos más críticos, o evaluar la robustez del modelo ante datos ruidosos o incompletos.

En conjunto, los resultados muestran que es posible predecir con alta fiabilidad los fallos en motores industriales usando aprendizaje automático supervisado y un buen preprocesado de datos.

En la siguiente fase del proyecto, se pretende extender el análisis hacia la predicción del tipo específico de fallo (`Failure Type`). Para ello, se plantea:
- Tratar `Failure Type` como una variable categórica (`factor`) y aplicar clasificación multiclase.
- Evaluar modelos como **Naive Bayes** para detectar patrones específicos.
- Usar **series temporales** si se dispone de datos secuenciales, lo que permitiría anticipar el fallo.
- Explorar la **teoría de colas** para modelar tiempos de espera y eficiencia del mantenimiento en entornos industriales.

### Segunda Entrega Intermedia:

En esta segunda entrega intermedia se han aplicado mejoras sustanciales al proyecto de predicción de fallos en motores eléctricos, partiendo de las observaciones recibidas en la primera evaluación. En particular, se corrigió el tratamiento de la variable `Type`, que en lugar de ser codificada mediante *one-hot encoding*, se ha tratado como un factor categórico, reduciendo así posibles problemas de colinealidad y mejorando la interpretación del modelo.

Además, se ha incorporado un análisis completo de la **multicolinealidad** utilizando el **Variance Inflation Factor (VIF)**, que ha confirmado que no existen redundancias estadísticas significativas entre los predictores. También se han evaluado los **residuos deviance** del modelo, mostrando una dispersión homogénea alrededor de cero sin patrones visibles, lo que indica que se cumplen razonablemente los supuestos de linealidad y homocedasticidad.

En cuanto al rendimiento del modelo, tanto la evaluación en el conjunto de test como la **validación cruzada de 10 particiones** han mostrado resultados perfectos, con una precisión (accuracy) y una medida de concordancia (Kappa) de 1.00. Si bien esto puede indicar un modelo altamente efectivo, también plantea dudas razonables sobre un posible **sobreajuste**, especialmente debido al uso de *up-sampling*, que puede favorecer la memorización de patrones.

Por tanto, aunque los resultados son técnicamente sólidos y estadísticamente coherentes, se recomienda mantener una visión crítica y ampliar el análisis en futuras fases del proyecto. Entre las posibles líneas de desarrollo se incluyen:

- Evaluar el modelo sobre un conjunto externo real no balanceado.
- Explorar algoritmos más complejos y robustos, como Random Forest o XGBoost.
- Extender el análisis a una clasificación multiclase basada en la variable `Failure Type`.
- Analizar la sensibilidad del modelo ante datos con ruido o registros incompletos.
- Incorporar métricas complementarias como curvas ROC, AUC o precisión-recall.

En conjunto, se concluye que el modelo actual proporciona una **base muy sólida** para la predicción de fallos en entornos industriales simulados, y sienta las bases para su validación y refinamiento en escenarios más realistas y exigentes.

### Tercera Entrega Intermedia:

En esta tercera y última entrega intermedia, se ha reforzado el carácter explicativo del trabajo con el objetivo de guiar al lector a lo largo del análisis, justificando cada decisión tomada. A raíz de los comentarios del profesor, se ha rediseñado completamente el apartado de análisis exploratorio (EDA), especificando qué variables se visualizan, por qué se seleccionan y qué se espera obtener con cada gráfico.

También se ha mejorado la narrativa de las fases de preprocesado, explicando detalladamente la conversión de variables categóricas, la eliminación de redundancias y el uso de técnicas de balanceo como el up-sampling. En particular, se ha aclarado el motivo por el que Target, a pesar de ser binaria, se convierte a factor: esto permite al motor de entrenamiento de caret tratarla correctamente como variable categórica durante la clasificación.

Uno de los puntos clave en esta revisión ha sido el análisis de residuos. En entregas anteriores, se había incluido un gráfico de residuos vs valores ajustados, siguiendo una lógica propia de modelos lineales. En esta versión, se ha decidido no generar dicho gráfico, explicando por qué no es aplicable en regresión logística y reconociendo explícitamente que su inclusión previa fue un error metodológico.

Por recomendación directa del profesor, también se ha incluido un experimento complementario con Naïve Bayes, comparando su rendimiento frente a la regresión logística. Los resultados han mostrado que, si bien la versión clásica del modelo (sin kernel) ofrece un rendimiento limitado, la variante con usekernel = TRUE alcanza una precisión del 99.93%, lo que valida la robustez de los datos y el preprocesado.

Si bien los resultados siguen siendo técnicamente impecables, se mantiene una postura prudente ante la posibilidad de sobreajuste. Como siguiente paso, se propone validar los modelos en condiciones más realistas y extender el análisis hacia tareas más complejas, como la predicción del tipo de fallo (Failure Type).

---

# Bibliografía

- Kuhn, M. and Johnson, K. (2013). *Applied Predictive Modeling*. Springer. ISBN 978-1-4614-6848-6.

- James, G., Witten, D., Hastie, T., and Tibshirani, R. (2021). *An Introduction to Statistical Learning with Applications in R*. 2ª edición. Springer.

- Bishop, C. M. (2006). *Pattern Recognition and Machine Learning*. Springer.

- UCI Machine Learning Repository. (2024). *Machine Predictive Maintenance Dataset*. Disponible en: https://archive.ics.uci.edu

- Hastie, T., Tibshirani, R. and Friedman, J. (2009). *The Elements of Statistical Learning: Data Mining, Inference, and Prediction*. Springer.

- Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), pp.5–32.
